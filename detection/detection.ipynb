{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1716385761.869426  125937 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1716385761.871203  126121 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.7), renderer: Mesa Intel(R) Arc(tm) Graphics (MTL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1716385761.931800  126102 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1716385761.949845  126103 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=True,\n",
    "                    model_complexity=1,\n",
    "                    smooth_landmarks=True,\n",
    "                    # enable_segmentation=True,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point(landmark):\n",
    "    return torch.tensor([landmark.x,-landmark.y])\n",
    "def angle(vec1, vec2):\n",
    "    cross_z = vec1[0] * vec2[1] - vec1[1] * vec2[0]\n",
    "    dot_product = torch.dot(vec1, vec2)\n",
    "    magnitude_vec1 = torch.norm(vec1)\n",
    "    magnitude_vec2 = torch.norm(vec2)\n",
    "    sin_theta = cross_z / (magnitude_vec1 * magnitude_vec2)\n",
    "    cos_theta = dot_product / (magnitude_vec1 * magnitude_vec2)\n",
    "    angle_rad = torch.atan2(sin_theta, cos_theta)\n",
    "    angle_deg = torch.rad2deg(angle_rad) % 360\n",
    "    \n",
    "    return angle_deg.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Esh = 20\n",
    "Elbow = 20\n",
    "Bsh = 30\n",
    "Blbow = 20\n",
    "\n",
    "def detectionBE(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(img)\n",
    "    rs = point(results.pose_landmarks.landmark[12])\n",
    "    ls = point(results.pose_landmarks.landmark[11])\n",
    "    re = point(results.pose_landmarks.landmark[14])\n",
    "    le = point(results.pose_landmarks.landmark[13])\n",
    "    rw = point(results.pose_landmarks.landmark[16])\n",
    "    lw = point(results.pose_landmarks.landmark[15])\n",
    "    rh = point(results.pose_landmarks.landmark[24])\n",
    "    lh = point(results.pose_landmarks.landmark[23])\n",
    "    rShoulder = angle(rs - re, rs - rh)\n",
    "    lShoulder = angle(ls - lh, ls - le)\n",
    "    rElow = angle(re - rw, re - rs)\n",
    "    lElow = angle(le - ls, le - lw)\n",
    "    #print(rShoulder,lShoulder, rElow, lElow)\n",
    "    #print(rs - re, rs - rh)\n",
    "    isEnd = (\n",
    "        0 <= rShoulder <= Esh\n",
    "        and 0 <= lShoulder <= Esh\n",
    "        and (180 - Elbow) < rElow < (180 + Elbow)\n",
    "        and (180 - Elbow) < lElow < (180 + Elbow)\n",
    "    )\n",
    "    isBegin = (\n",
    "        90 <= rShoulder <= 90 + Bsh\n",
    "        and 90 <= lShoulder <= 90 + Bsh\n",
    "        and (180 - Blbow) < rElow < (180 + Blbow)\n",
    "        and (180 - Blbow) < lElow < (180 + Blbow)\n",
    "    )\n",
    "    return isBegin,isEnd;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, True)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"2.jpg\")\n",
    "print(detectionBE(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mp_pose.Pose()其参数：\n",
    "\n",
    "1. static_image_mode：静态图像还是连续帧视频;\n",
    "\n",
    "2. model_complexity：人体姿态估计模型,0表示速度最快,精度最低（三者之中）,1表示速度中间，精度中间（三者之中),2表示速度最慢，精度最高（三者之中）;\n",
    "\n",
    "3. smooth_landmarks：是否平滑关键点；\n",
    "\n",
    "4. enable_segmentation：是否对人体进行抠图;\n",
    "\n",
    "5. min_detection_confidence：检测置信度阈值；\n",
    "\n",
    "6. min_tracking_confidence：各帧之间跟踪置信度阈值；"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
